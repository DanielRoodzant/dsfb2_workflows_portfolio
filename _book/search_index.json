[["index.html", "R portfolio Daniël Roodzant Introduction", " R portfolio Daniël Roodzant Daniël Roodzant 2021-06-11 Introduction Welcome to my bookdown portfolio. Here I will show you some of the coding skills I have gathered. Lets start with my CV which I have created using the pagedown package: My CV "],["c-elegans-plate-experiment.html", "C. elegans plate experiment", " C. elegans plate experiment The data for this exercise was kindly supplied by J. Louter (INT/ILC) and was derived from an experiment in which adult C.elegans nematodes were exposed to varying concentrations of different compounds. The variables RawData (the outcome - number of offspring counted as an integer value, after incubation time), compName (the generic name of the compound/chemical), the compConcentration (the concentration of the compound), and the expType are the most important variables in this dataset. A typical analysis with this data would be to run a dose-response analysis using a log-logistic model with estimates for the maximal, the minimal, the IC50 concentration and the slope at IC50. We will not go into the details but a good package to run such computations and create graphs in R is the {drc} package. Lets have a look at the excel file containing the data. We can see that someone put a lot of care into the make-up of the sheet and it is still difficult to read. Now lets open the Excel file in R and render the first five rows. scatter_FLOW.062 &lt;- read_excel(&#39;data/data_raw/CE.LIQ.FLOW.062_Tidydata.xlsx&#39;) knitr::kable( scatter_FLOW.062 %&gt;% head(5)) plateRow plateColumn vialNr dropCode expType expReplicate expName expDate expResearcher expTime expUnit expVolumeCounted RawData compCASRN compName compConcentration compUnit compDelivery compVehicle elegansStrain elegansInput bacterialStrain bacterialTreatment bacterialOD600 bacterialConcX bacterialVolume bacterialVolUnit incubationVial incubationVolume incubationUnit incubationMethod incubationRPM bubble incubateTemperature NA NA 1 a experiment 3 CE.LIQ.FLOW.062 2020-11-30 Sergio Reijnders - Ellis Herder 68 hour 50 44 24157-81-1 2,6-diisopropylnaphthalene 4.99 nM Liquid controlVehicleA N2 25 OP50 heated 0.743 8 300 ul 1,5 glass vial 1000 ul rockroll 35 NA 20 NA NA 1 b experiment 3 CE.LIQ.FLOW.062 2020-11-30 Sergio Reijnders - Ellis Herder 68 hour 50 37 24157-81-1 2,6-diisopropylnaphthalene 4.99 nM Liquid controlVehicleA N2 25 OP50 heated 0.743 8 300 ul 1,5 glass vial 1000 ul rockroll 35 NA 20 NA NA 1 c experiment 3 CE.LIQ.FLOW.062 2020-11-30 Sergio Reijnders - Ellis Herder 68 hour 50 45 24157-81-1 2,6-diisopropylnaphthalene 4.99 nM Liquid controlVehicleA N2 25 OP50 heated 0.743 8 300 ul 1,5 glass vial 1000 ul rockroll 35 NA 20 NA NA 1 d experiment 3 CE.LIQ.FLOW.062 2020-11-30 Sergio Reijnders - Ellis Herder 68 hour 50 47 24157-81-1 2,6-diisopropylnaphthalene 4.99 nM Liquid controlVehicleA N2 25 OP50 heated 0.743 8 300 ul 1,5 glass vial 1000 ul rockroll 35 NA 20 NA NA 1 e experiment 3 CE.LIQ.FLOW.062 2020-11-30 Sergio Reijnders - Ellis Herder 68 hour 50 41 24157-81-1 2,6-diisopropylnaphthalene 4.99 nM Liquid controlVehicleA N2 25 OP50 heated 0.743 8 300 ul 1,5 glass vial 1000 ul rockroll 35 NA 20 And have a look at the data types. scatter_FLOW.062 %&gt;% select(RawData, compName, compConcentration) %&gt;% head(1) ## # A tibble: 1 x 3 ## RawData compName compConcentration ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 44 2,6-diisopropylnaphthalene 4.99 When we have a look at some of the data types of the collumns RawData, compName and compConcentration (see above) we would expect them to be dbl, chr and dbl. compConcentration however, has the datatype chr. This means it was imported incorrectly. Next we will create a scatterplot graph with the data for the different compounds and the varying concentrations. To do this I first fixed the compConcentration column by making it numeric, put the compConcentration on the x-axis, the RawData counts on the y-axis and assigned a color to each level in compName. I also assigned a different symbol to each level by the expType variable. # Transform the datatype of compConcentration to dbl scatter_FLOW.062 &lt;- scatter_FLOW.062 %&gt;% transform(compConcentration = as.double(compConcentration)) # Plotting data using ggplot scatter_FLOW.062 %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_point(aes(colour = compName, shape = expType)) + labs(title = &quot;Compound RawData per compound concentration&quot;, caption = &quot;Data supplied by J. Louter (INT/ILC)&quot;) If I would not have changed the data type of the compConcentration column this would have happened: # Show example of the wrong graph gotten from .xlsx format by retrieving data and plotting it wrong_scatter_FLOW.062 &lt;- read_excel(&#39;data/data_raw/CE.LIQ.FLOW.062_Tidydata.xlsx&#39;) wrong_scatter_FLOW.062 %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_point(aes(colour = compName, shape = expType)) + labs(title = &quot;Compound RawData per compound concentration&quot;, caption = &quot;Data supplied by J. Louter (INT/ILC)&quot;) Every concentration is seen as a separate point because the column has the ‘chr’ type. Now, with the correct data types we will tweak the graph using a log10 transformation on the x-axis to get a clear graph. I also added a bit of jitter to prevent the points in the graph from overlapping. # Plot data using log10 function in ggplot scatter_FLOW.062 %&gt;% ggplot(aes(x = compConcentration, y = RawData)) + geom_point() + geom_jitter(aes(colour = compName, shape = expType), width = 0.5) + scale_x_log10() + labs(title = &quot;Compound RawData per compound concentration&quot;, caption = &quot;Data supplied by J. Louter (INT/ILC)&quot;) The positive control for this experiments is ethanol. The negative control for this experiment is S-medium. To analyze this experiment and learn whether there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve (IC50) I would take these steps: - Group the data for every compound. - Check if the data is normally distributed. - Use the apropriate statistical tests on the data to see if there is a statistically significant effect of different concentrations on the offspring count. - Calculate the IC50 and create a plot of the curve. For the next vizualization of the data I have normalised the data Normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and that all other values are expressed as a fraction thereof. Rerun your graphs with the normalized data. # Calculate the mean of the RawData mean_data_FLOW.062 &lt;- scatter_FLOW.062 %&gt;% select(expType, RawData, compName, compConcentration) %&gt;% group_by(expType) %&gt;% filter(expType == &#39;controlNegative&#39;) %&gt;% summarise(mean_RawData = mean(RawData, na.rm = TRUE)) # Normalise the RawData using the calculated mean normalized_FLOW.062 &lt;- scatter_FLOW.062 %&gt;% select(expType, compName, compConcentration, RawData) %&gt;% mutate(RawData_normalized = RawData / mean_data_FLOW.062$mean_RawData) # Calculate the mean of the normalised data mean_normalized_FLOW.062 &lt;- normalized_FLOW.062 %&gt;% group_by(expType, compName, compConcentration) %&gt;% summarise(mean_RawData_normalized = mean(RawData_normalized, na.rm = TRUE)) knitr::kable(mean_normalized_FLOW.062 %&gt;% head(5)) expType compName compConcentration mean_RawData_normalized controlNegative S-medium 0.00e+00 1.0000000 controlPositive Ethanol 1.50e+00 0.5750873 controlVehicleA Ethanol 5.00e-01 1.0690726 experiment 2,6-diisopropylnaphthalene 4.99e-05 1.0391929 experiment 2,6-diisopropylnaphthalene 4.99e-04 0.9670159 # Plot the normalised mean using ggplot mean_normalized_FLOW.062 %&gt;% ggplot(aes(x = compConcentration, y = mean_RawData_normalized)) + geom_point() + geom_jitter(aes(colour = compName, shape = expType), width = 0.5) + labs(title = &quot;Normalized mean compound RawData per compound concentration&quot;, caption = &quot;Data supplied by J. Louter (INT/ILC)&quot;) I took this step to get the result in relation to the ‘0 value’ which makes it easier to compare the samples to the “normal” value. "],["open-peer-review.html", "Open Peer Review", " Open Peer Review This exercise is about identifying reproducibility issues in a scientific publication. We use the criteria for reproduciblity that are publicly available. (#tab:read criteria table)Reproducibility criteria Transparency Criteria Definition Response Type Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. Binary Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. Binary Data Location Where the article’s data can be accessed, either raw or processed. Found Value Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. Binary; Found Value Author Review The professionalism of the contact information that the author has provided in the manuscript. Found Value Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. Binary Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. Binary Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. Binary Table clarification The Transparency Criteria are criteria needed to score an article of your choice. Each Transparency criterion comes with a Definition that explains the criterion in more details. These descriptions are particularly helpful to understand what the criterion entails and what to look for in the article. The Response Type is the actual score. resource I found an open access scientific article using PubMed and scored it using the table above. Article: Yamayoshi S, Sakai-Tagawa Y, Koga M, et al. Comparison of Rapid Antigen Tests for COVID-19. Viruses. 2020;12(12):1420. Published 2020 Dec 10. doi:10.3390/v12121420 Study purpose - Present Data availability statement - Not present Data location - Present Study location - Present Author review - Not present Ethics statement - Present Funding statement - Present Code availability - Not present In the study rapid antigen tests (RAT) for covid-19 are tested on corona positive patients to compare their effectivity to the PCR method. To do this patient material such as saliva and nose/throat swabs were used with four types of RATs and the standard PCR test. The RATs were also tested using 2 isolated virus strands. The RATs were less sensitive than the PCR test. Some of the RATs are not able to detect low quantities of virusparticles. There is no big difference between the isolated virus and the clinical samples. Data is available onine here Next I used the OSF website to select a project that adresses an aspect of the SARS-Cov-2 virus and contained a dataset and R-code in the project enviorment. I found the project Bats and COVID-19 The code in this project intends to compare the search words ‘coronavirus’ and ‘bats’ through Google and wikipedia in multiple countries and score how often they were used together. The readability of the code is a 4/5. Click here to see the full code from the article. &lt;br Now lets reproduce some of the code: ###################### ###Fig.1 (2016-2020 US Tv news about bats) {.unnumbered} { tv.dat &lt;- read.csv(file=&quot;data/data_raw/GDELTBatsUS1620.csv&quot;) tv.dat$date &lt;- ymd(tv.dat$date) tv.dat[61, &quot;date&quot;] &lt;- &quot;2021-01-01&quot; tv.dat[61, &quot;value&quot;] &lt;- NA tv.dat[61, &quot;X&quot;] &lt;- 61 ggplot() + geom_line(data=tv.dat, aes(x=X, y=value), size=0.8, color=&quot;steelblue&quot;, linetype=&quot;solid&quot;) + theme_bw() + scale_x_continuous(breaks=c(1, 13, 25, 37, 49, 61), labels=c(&quot;2016&quot;, &quot;2017&quot;, &quot;2018&quot;, &quot;2019&quot;, &quot;2020&quot;, &quot;2021&quot;)) + theme(axis.text.x = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.text.y = element_text(colour=&quot;black&quot;,size=14,angle=0,hjust=1,vjust=0,face=&quot;plain&quot;), axis.title.x = element_text(colour=&quot;black&quot;,size=12,angle=0,hjust=.5,vjust=.5,face=&quot;plain&quot;), axis.title.y = element_text(colour=&quot;black&quot;,size=12,angle=90,hjust=.5,vjust=.5,face=&quot;plain&quot;), plot.title = element_text(size=22, face=&quot;bold&quot;)) + theme(strip.background =element_rect(fill=&quot;wheat&quot;)) + labs(x=&quot;&quot;, y=&quot;&quot;) + theme(strip.text = element_text(colour = &quot;black&quot;, size=14, face=&quot;bold&quot;)) } ################################## Errors: Adjusted data location and loaded library lubridate. It took very low effort (4/5) to reproduce the code. "],["portfolio-assignment-2.html", "Portfolio assignment 2 Assignment", " Portfolio assignment 2 Assignment Applying the Guerrilla analytics framework to your own project. A 1. Look at your RStudio project that you created for the DAUR-II final assignment 2. Rearrange your project according the Guerilla principles explained above 3. Add README files to the datasets 4. Use the {fs} package to share a screenshot of your folder tree in your portfolio, look at: for more info on how to use the {fs} package. ## . ## ├── 001_portfolio_assignment_1.1.Rmd ## ├── 002_portfolio_assignment_1.2.Rmd ## ├── 003_portfolio_assignment_2.Rmd ## ├── 004_portfolio_assignment_3.Rmd ## ├── 005_portfolio_assignment_5.Rmd ## ├── 006_portfolio_assignment_6.1.Rmd ## ├── 007_portfolio_assignment_6.2.Rmd ## ├── 008_portfolio_assignment_7.Rmd ## ├── WorkflowsPortfolio.Rproj ## ├── _book ## │ ├── _main_files ## │ │ └── figure-html ## │ │ ├── 1.1.d-1.png ## │ │ ├── 1.1.e-1.png ## │ │ ├── 1.1.f-1.png ## │ │ └── 1.1.j-1.png ## │ ├── c-elegans-plate-experiment.html ## │ ├── data ## │ │ ├── Untidy_example.png ## │ │ ├── _CV_Daniël_Roodzant.pdf ## │ │ ├── _introduction.Rmd ## │ │ ├── _introduction.html ## │ │ └── data_raw ## │ │ ├── CE.LIQ.FLOW.062_Tidydata.xlsx ## │ │ ├── Untidy_example.png ## │ │ └── bats_and_covid.R ## │ ├── index.html ## │ ├── libs ## │ │ ├── anchor-sections-1.0.1 ## │ │ │ ├── anchor-sections.css ## │ │ │ └── anchor-sections.js ## │ │ ├── gitbook-2.6.7 ## │ │ │ ├── css ## │ │ │ │ ├── fontawesome ## │ │ │ │ │ └── fontawesome-webfont.ttf ## │ │ │ │ ├── plugin-bookdown.css ## │ │ │ │ ├── plugin-clipboard.css ## │ │ │ │ ├── plugin-fontsettings.css ## │ │ │ │ ├── plugin-highlight.css ## │ │ │ │ ├── plugin-search.css ## │ │ │ │ ├── plugin-table.css ## │ │ │ │ └── style.css ## │ │ │ └── js ## │ │ │ ├── app.min.js ## │ │ │ ├── clipboard.min.js ## │ │ │ ├── jquery.highlight.js ## │ │ │ ├── lunr.js ## │ │ │ ├── plugin-bookdown.js ## │ │ │ ├── plugin-clipboard.js ## │ │ │ ├── plugin-fontsettings.js ## │ │ │ ├── plugin-search.js ## │ │ │ └── plugin-sharing.js ## │ │ ├── header-attrs-2.7 ## │ │ │ └── header-attrs.js ## │ │ ├── header-attrs-2.8 ## │ │ │ └── header-attrs.js ## │ │ └── jquery-2.2.3 ## │ │ └── jquery.min.js ## │ ├── my-plan.html ## │ ├── open-peer-review.html ## │ ├── portfolio-assignment-1-1.html ## │ ├── portfolio-assignment-1-2.html ## │ ├── portfolio-assignment-2.html ## │ ├── portfolio-assignment-3.html ## │ ├── portfolio-assignment-5.html ## │ ├── portfolio-assignment-6-1.html ## │ ├── portfolio-assignment-6-2.html ## │ ├── portfolio-assignment-7.html ## │ └── search_index.json ## ├── _bookdown_files ## ├── _main.Rmd ## ├── _main_files ## │ └── figure-html ## │ ├── 1.1.d-1.png ## │ ├── 1.1.e-1.png ## │ ├── 1.1.f-1.png ## │ ├── 1.1.j-1.png ## │ └── bats_and_covid.R code-1.png ## ├── data ## │ ├── _CV_Daniël_Roodzant.Rmd ## │ ├── _CV_Daniël_Roodzant.html ## │ ├── _CV_Daniël_Roodzant.pdf ## │ ├── _introduction.Rmd ## │ ├── _introduction.html ## │ ├── data_raw ## │ │ ├── CE.LIQ.FLOW.062_Tidydata.xlsx ## │ │ ├── GDELTBatsUS1620.csv ## │ │ ├── Untidy_example.png ## │ │ ├── bats_and_covid.R ## │ │ └── reproducibility_criteria.xlsx ## │ ├── dengue_data.csv ## │ ├── flu_data.csv ## │ └── portfolio_5b.bib ## └── index.Rmd B Now clean up your work environment for this course (workflows) and the parallel course in DSFB2 (projecticum). Set up a folder structure that will accomodate future plans and collaboration on the projecticum. Provide readme-files or comments within the code where needed. For the projecticum folder, make sure you do this together with your lab partner. "],["portfolio-assignment-3.html", "Portfolio assignment 3 Assignment CV", " Portfolio assignment 3 Assignment Start your portfolio with a CV A Create a Git repository on GitHub for your portfolio. Subsequently, clone the GitHub repository to your computer. Copy paste your portfolio-Rmd-files to this folder. You will see the new files showing up in the “git” window in the upper right of the screen in Rstudio. Commit/push the changes to your repo. B Now start building your CV in a new Rmarkdown file and keep using github for version control. Remember to commit often, and push your changes! Build something that you would want to send to a possible future bioinformatics internship position, or when job hunting. So it needs to be complete and professional looking. You can look around online for examples of cv’s (/resume). Your cv will be part of your portfolio. CV My CV "],["portfolio-assignment-5.html", "Portfolio assignment 5 Assignment Projecticum introduction", " Portfolio assignment 5 Assignment A Make sure you have: 1. Two personal repositories on github: one for your portfolio, one for the regular exercises. 2. One repo in the projecticum organisation, that you share with your partner. 3. Your local repositories are up to date with the main for all three of them. 4. A github project, with kanban board filled with issues connected to the projecticum repository. 5. One (separate!) .Rmd file for each of your projecticum assignments. 6. Three local (i.e. on your laptop) Rstudio projects: projecticum, portfolio and regular_assignments. (you may have given them other names, that’s fine) B 1. Make a new folder within Mendeley for the projecticum. Place all pdf’s you used till now in your folder (if you did not use any papers as source yet, find 3 papers on Pubmed now that you could use for your introduction.). Copy your .bib file to the folder on your computer you are using for the Projecticum git repo. 2. Start a .Rmd named “introduction.Rmd” with a few lines introduction on your projecticum topic. 3. Include automatic inline references to the papers you used. 4. The bibliography will be placed at the end of the document. Provide an appropriate header. 5. Merge your work with that of your projecticum partner through github. Solve all the problems you encounter. If github does not want to merge .bib files and you want a merged one, try here. 6. Find out how you can add websites as reference to Mendeley. 7. Write (so not “copy!”) at least 500 words of introduction for your projecticum project and use at least 5 references. Projecticum introduction View here "],["portfolio-assignment-6-1.html", "Portfolio assignment 6.1 Assignment", " Portfolio assignment 6.1 Assignment github pages Execute the steps explained here (click) to setup a github-pages repository called myname-portfolio or something similar. Once you have successfully rendered your bookdown to a full website, hosting can be achieved by copying all html files to your Github-pages. The easiest way is to: clone your github pages repo copy all the html files rendered with bookdown to this folder commit and push all changes to your github pages repo. The website will be automatically updated after some time. You can also setup a theme for your github pages. See here for more info, but you have learned to use css, so this is a nice opportunity to display that. Put your portfolio on your github pages Send the url to your public portfolio address on the “prikbord” channel. "],["portfolio-assignment-6-2.html", "Portfolio assignment 6.2 Assignment My plan", " Portfolio assignment 6.2 Assignment looking ahead In class, we discussed this assignment yesterday. In the following weeks, start looking for what you will want to spend your extra time on this semester. Try, for yourself, to answer the following questions: Where do I want to be in ~2 years time? How am I doing now with respect to this goal? What would be the next skill to learn? Make a planning on how to start learning this new skill. Note the following points: It has to be life sciences or useful for life sciences (no knitting, riding horses etc) It has to be data science / bioinformatics You have to show your plan in your portfolio, together with the result of the first few steps you took in trying to rech this goal. You probably won’t learn this skill in a few days. Just get started. This assignment will show us whether you succeeded in reaching an overview of the field and possibilities in data science for biology. My plan In 2 years time I want to be working as a data scientist for a research group most preferably in the field of genomics or proteomics. This minor program is my first big step and also my first big inspiration in regards to bioinformatics and data science. The next skill for me to learn would be expanding my coding knowledge wherever necessary. I will start this by getting online certificates through the Coursera platform. Here, institutes like universities but also Google and IBM offer courses, certificate programs and degrees in a number of fields including data science. There is a number of certificates you can get free of charge that will be a nice touch on your resume and a big step forward in you coding or data science career. In this process I would also like to learn Python and some more HTML. "],["portfolio-assignment-7.html", "Portfolio assignment 7 Assignment", " Portfolio assignment 7 Assignment relational databases TIPS Be aware, the flu and dengue data contains metadata that should be stripped from the data on load. Think of a way to create valid country names that fit with the gapminder data. Remember (!) that in the end, this assignment needs to be reported by a .Rmd file for your portfolio. So save what you are doing, save your SQL scripts, make screenshots if you want, and in general design a clear and attractive report in RMarkdown to showcase your SQL/database-skills in your portfolio. You may be sending this to propspective employers in the future! (also, the portfolio is what we as teachers will be grading. But definitely think about the future rather than only about “passing the course”) Assignment Load the flu (“./data/flu_data.csv), the dengue (.”/data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R Check if they are in the right shape. Is the data in the ‘tidy’ format? If not change the format to ‘tidy’ Change the country and date variables of the three tables so that they coincide in terms of data type, class and values Store the three tables as separate (so six in total) .csv and .rds files. In Dbeaver create a new PostgreSQL database “workflowsdb” Using RPostgreSQL, insert the tables into the database. Inspect the contents of the tables with SQL (in DBeaver) and save the SQL script. Inspect the contents of the tables with dplyr (in R) and save a RMarkdown showing what you are doing. Load the gapminder data in R and change the dataframe in such as way that you could join it to dengue and flue. Save this clean gapminder data in the “workflowsdb” database Perform some joins (your choice) with SQL (can be done in DBeaver or with dplyr. Generate a joined table, and export this from the database to R. Show some descriptive statistics with this table, and at least 3 visualisations using ggplot2. show all of your actions in this assignment in a Rmd file, perhaps with pictures and provide text explaining and showcasing your skills. flu_data &lt;- read.csv(&#39;data/flu_data.csv&#39;, skip = 11) dengue_data &lt;- read.csv(&quot;data/dengue_data.csv&quot;, skip = 11) gapminder &lt;- dslabs::gapminder flu_data &lt;- flu_data %&gt;% tidyr::pivot_longer(cols = Argentina:Uruguay, names_to = &quot;country&quot;, values_to = &quot;value&quot;) dengue_data &lt;- dengue_data %&gt;% tidyr::pivot_longer(cols = Argentina:Venezuela, names_to = &quot;country&quot;, values_to = &quot;value&quot;) "]]
